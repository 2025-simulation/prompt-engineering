#+title: README

Use prompt-engineering to enhanced and limit the AI performance. 

* Turn on knowledge base in Cherry Studio
1. in the Settings -> Model Provider -> Gemini -> Manage -> Embedding -> add one model
   
2. on the left tabs in the Cherry Studio, click *Knowlege Base*. Then add one. 

3. Finally drag specific file in it. Then enable kowledge base when communicating with AI. 


* The most helpful prompt-tech
1. Prompt Chaining
   语言中使用分步来提示。
   #+begin_src text
     你是一个很有帮助的助手。你的任务是根据文档回答问题。第一步是从文档中提取与问题相关的引文，由####分隔。请使用<quotes></quotes>输出引文列表。如果没有找到相关引文，请回应“未找到相关引文！”。
   
     ####
     {{文档}}
     ####
   #+end_src
   
2. 思维树 ToT
   非单一专家，发散思考，同时检查。
   #+begin_src text
     假设三位不同的专家来回答这个问题。
     所有专家都写下他们思考这个问题的第一个步骤，然后与大家分享。
     然后，所有专家都写下他们思考的下一个步骤并分享。
     以此类推，直到所有专家写完他们思考的所有步骤。
     只要大家发现有专家的步骤出错了，就让这位专家离开。
     请问...
   #+end_src 

3. 检索增强生成 [[https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/][RAG]]
   接受输入并检索出一组旺端，作为上下文和输入的原始提示词组合。
   可能可以用来学习新的编程语言，这个部分需要深入学习。
   适用于知识密集型任务中增强语言模型输出。
   
   很多问题解决需要基本的常识。而 AI 的基本常识在训练的时候使用的数据集就已经限制了他的基本常识储量。
   当然 AI 在对话的时候也可以做到补充常识，但是大量的基础知识补充通过对话补充是复杂的。当然现在 AI 也可以通过联网的方式补充，这受限于网络的知识储量。
   
   如果我们有大量的新的知识需要补充就可以利用 RAG。
   
4. Active-Prompt
   第一步是使用或不使用少量 CoT 示例查询 LLM。对一组训练问题生成 k 个可能的答案。基于 k 个答案计算不确定度度量（使用不一致性）。选择最不确定的问题由人类进行注释。然后使用新的注释范例来推断每个问题。
   
   或许可以用来辅助注释文档的生成。

5. 自我反思 Reflexion
   越多的实践，提升越多，但是如何支持越来越长的上下文。
